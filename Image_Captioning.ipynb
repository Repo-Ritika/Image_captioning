!pip install --upgrade ipywidgets jupyterlab_widgets transformers pillow requests torch

import requests
import torch
from PIL import Image
from transformers import VisionEncoderDecoderModel, GPT2TokenizerFast, ViTImageProcessor
import urllib.parse as parse
import os
from IPython.display import display

finetuned_model = VisionEncoderDecoderModel.from_pretrained("nlpconnect/vit-gpt2-image-captioning").to(device)
finetuned_tokenizer = GPT2TokenizerFast.from_pretrained("nlpconnect/vit-gpt2-image-captioning")
finetuned_image_processor = ViTImageProcessor.from_pretrained("nlpconnect/vit-gpt2-image-captioning")

def is_url(string):
    try:
        result = parse.urlparse(string)
        return all([result.scheme, result.netloc, result.path])
    except:
        return False

def load_image(image_path):
    if is_url(image_path):
        response = requests.get(image_path, stream=True)
        response.raise_for_status()
        return Image.open(response.raw).convert("RGB")
    elif os.path.exists(image_path):
        return Image.open(image_path).convert("RGB")
    else:
        raise ValueError("Invalid image path or URL")

def get_caption(model, image_processor, tokenizer, image_path):
    image = load_image(image_path)
    img = image_processor(image, return_tensors="pt").to(device)
    output = model.generate(**img, max_length=50)
    caption = tokenizer.batch_decode(output, skip_special_tokens=True)[0]
    return caption

url = "https://bigcatsindia.com/wp-content/uploads/2018/06/Royal-Bengal-Tiger.jpg"
display(load_image(url))
caption = get_caption(finetuned_model, finetuned_image_processor, finetuned_tokenizer, url)
print("Generated Caption:", caption)
